\documentclass[12pt, leqno]{article}
\usepackage{amsthm}
\input{common}

\newtheorem{lemma}{Lemma}

\begin{document} \phdr{Proj 1: All Roads Lead to Fresno}

There are many problems that involve optimizing some objective
function by making local adjustments to a structure or graph.
For example:
\begin{itemize}
\item If we want to reinforce a truss with a limited budget, where
  should we add new beams (or strengthen old ones)?
\item After a failure in the power grid, how should lines be either
  taken out of service or put in service to ensure no other lines
  are overloaded?
\item In a road network, how will road closures or rate-limiting of
  on-ramps affect congestion (for better or worse)?
\item In a social network, which edges are most critical to
  spreading information or influence to a target audience?
\end{itemize}

In many cases, translating the original physical problem into a
mathematical model is itself a difficult challenge.  Rather than
working with a ``real-world'' model, we are going to focus in this
project on a toy model that has many real-world characteristics.  Of
course, in the process we also want to exercise your knowledge of
linear systems, norms, and the like!

\section*{Logistics}

{\bf You are encouraged to work in pairs on this project.}  You should
produce short report addressing the analysis tasks, and a few
short codes that address the computational tasks.  You may
use any MATLAB functions you would want.

You should be able to convince both me and your fellow students that
your code is right.  A good way to do this is to test thoroughly.
Check residuals, compare cheaper or more expensive ways of computing
the same thing, and generally use the computer to make sure you don't
commit silly errors in algebra or coding.  You will also want to make
sure that you satisfy the efficiency constraints stated in the tasks.

You will have ten days to work on the project, at which time you
should submit your report and code.  This will be reviewed by two
other students, following guidelines that I will distribute, after
which you will have the chance to change things.

\section*{The Story}

A driver in California leaves his home and promptly gets lost.  The
driver wants to reach some target (e.g.~Fresno), but in fact ends up
wandering at random until he is exhausted.  Our goal is to close one
road to maximally improve the expected time the driver sill spend at
his target.

Mathematically, we model the road network topology by an adjacency
matrix $A \in \bbR^{n \times n}$, where $n$ is the number of
intersections or destinations and
\[
  A_{ij} =
  \begin{cases}
    1, & \mbox{ if a road connects $i$ to $j$} \\
    0, & \mbox{ otherwise}.
  \end{cases}
\]
The driver treats all roads as equally plausible, and so we have
\[
  T_{ij} = A_{ij}/d_j
\]
as the probability that a driver at node $j$ will choose to take
the rode to node $i$, where $d$ is the degree of node $j$.

Our driver follows one road per step.  At each step he keeps going
with probability $\alpha = 0.9$, and gives up (or runs out of gas) with
probability $1-\alpha$.  Thus, if the driver starts at node $s$,
the expected number of times we expect he will visit a target node
$t$ is
\[
  f = \sum_{k=0}^\infty (\alpha T^k)_{ts} = \left[ (I-\alpha T)^{-1} \right]_{ts}.
\]
Our goal is to find one road $(a,b)$ whose closure most increases $f$.
That is, we want to change the $A_{ab}$ from a one to a zero in order
to increase $f$.  Moreover, we want to do this fast.

\section*{Getting Started}

We will be using the California road network data from the SNAP data
set; you can retrieve this as a MATLAB M-file from
\begin{center}
  http://www.cise.ufl.edu/research/sparse/matrices/SNAP/roadNet-CA.html
\end{center}
This is a big enough network that you will {\em not} want to form it,
or its inverse, as a dense matrix.  On the other hand, because it is a
moderate-sized planar graph, sparse Gaussian elimination
on $I-\alpha T$ will work fine.

Once you have downloaded the data set, you can use the following code
to form the matrix $M = I-\alpha T$:
\lstinputlisting{proj1code/problem_load.m}

As a test case, you might want to consider trying to get your random
walker to start at node $1$ and arrive at node $180$.

\paragraph*{Task 1}
Solve the linear system $Mu = e_1$ using MATLAB's sparse backslash
operator, where $e_1$ is the first column of the identity matrix.
Using the {\tt tic} and {\tt toc} commands, approximately how long
does this computation take?

\paragraph*{Task 2}
Look at the documentation for the MATLAB {\tt lu} command, and figure
out how to do an LU decomposition of $M$ with column pivoting (for
sparsity) as well as row pivoting.  That is, you will compute a
decomposition
\[
  PMQ = LU.
\]
For this problem, you should find that $PQ = I$; verify that this is
true.  Can you figure out why?

\paragraph*{Task 3}
We can write the matrix $M$ as $M = N D^{-1}$ where $N = D-\alpha A$
and $D$ is a diagonal matrix of degrees.  Argue that in this case,
$N$ is symmetric and positive definite for $\alpha < 1$.

\paragraph*{Task 4}
Given either the sparse Cholesky (with variable reordering) or sparse
LU (with column pivoting), write a short MATLAB expression to solve
$Mu = e_1$ without re-factoring $M$ (which is what happens if you use
the backslash operator on $M$ directly).

{\bf Notes:} For Tasks 2-3 (particularly Task 2), it will be helpful
to look up the concept of {\em diagonal dominance} (it's mentioned
briefly in the book in the discussion of Gaussian elimination).  A
matrix $M$ is {\em strictly (column) diagonally dominant} if the
magnitudes of diagonal elements are bigger than the sum of the
magnitudes of off-diagonal elements; that is,
\[
  \forall i, ~ |m_{ii}| > \sum_{j \neq i} |m_{ij}|.
\]
  
A strictly diagonally dominant matrix is automatically nonsingular,
since if $D$ is the diagonal of the matrix, then
\[
  D^{-1} M = I + D^{-1} (M-D)
\]
and $\|D^{-1} (M-D)\|_1 < 1$.  Therefore, we can write down the
inverse as a convergent series (called a geometric series or a Neumann
series depending on context), just as we did when setting up this
problem.

Factoring a strictly diagonally dominant matrix also involves
{\em no pivoting} when performing Gaussian elimination with partial
pivoting.

\section*{The Optimization}

Your goal is to maximize
\[
  f(a,b) = e_t^T \hat{M}(a,b)^{-1} e_s
\]
where $\hat{M}(a,b)$ is the matrix associated with removing the edge
$(a,b)$.  For example, in the road network,
$(M^{-1})_{180,1} = 0.1176178$, but
$(\hat{M}(1,2)^{-1})_{180,1} = 0.1788743$.  It turns out that this is
the edge removal that maximizes this element.  On my laptop,
a back-of-the-envelope calculation suggests that it would take most
of a year to do this computation naively.  On the other hand,
I was able to run the computation in about 15 seconds on my laptop
using a few tricks, which I hope you will try to replicate.

You do {\em not} want to have to form, factor, and solve
a linear system involving $\hat{M}(a,b)$ for every edge $(a,b)$ in
the network; you'll want to be smarter than that.  We will use
two tricks: low rank structure and norm bounds.

\paragraph*{Task 5}
Show how to write $\hat{M}(a,b)$ as a simple rank-2 update to $M$.
Alternately, you may do the same thing for the matrix $\hat{N}(a,b)$
and $N$ (where $M = ND^{-1}$ as above).

\paragraph*{Task 6}
The {\em Sherman-Morrison-Woodbury} formula says that if $B$, $C$, and
$B+UCV$ are all invertible, then
\[
  (B + UCV^T)^{-1} = B^{-1} - B^{-1} U (C^{-1} + V^T B^{-1} U)^{-1} V^T B^{-1}.
\]
Write a routine using this formula
to accelerate the computation of $f(a,b)$.  In addition to taking
advantage of the LU factorization of $M$ (or the Cholesky
factorization of $N$), you should try to precompute as much as
possible so that you don't have to solve too many linear systems.

\paragraph*{Task 7} (Extra credit)
Find a way to bound
\[
  f(a,b) - e^T M^{-1} e_s
\]
that does not require any additional linear solves after
pre-processing.  For example, if $t \not \in \{a, b\}$,
one can show
\[
|f(a,b) - e^T M^{-1} e_s| \leq
\frac{1}{d_t}
\left( \frac{1+\alpha}{1-\alpha} \right)
\left( \frac{w_a}{d_a-1} + \frac{w_b}{d_b-1} \right).
\]
where $d_k$ is the degree of the node $k$ (before the update)
and $w = N^{-1} e_t$.

\paragraph*{Task 8} (Extra credit)
Combine the results of tasks 6-7 to find the optimal edge, neglecting
any edges from consideration that change the value of $f$ by less than
a tolerance $\tau = 10^{-3}$.  You may also neglect any edge involving
a degree one node.

\paragraph*{Notes:}
Actually proving the bound in Task 7 is tricky, and is worth
significant extra credit.  Using the bound as specified in Tasks 7 and
8 is more straightforward, and is worth a more modest bonus (but nontrivial).


\end{document}
